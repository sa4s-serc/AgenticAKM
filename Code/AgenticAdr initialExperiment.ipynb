{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdc3cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LAB\\ADR\\AgenticAdr\n"
     ]
    }
   ],
   "source": [
    "cd D:\\LAB\\ADR\\AgenticAdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502afb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Union\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- Configuration ---\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38a7cf",
   "metadata": {},
   "source": [
    "### RepoSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f39ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepoSummarizer:\n",
    "    \"\"\"\n",
    "    An agent to summarize a code repository using an LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: genai.GenerativeModel):\n",
    "        \"\"\"\n",
    "        Initializes the summarizer with a specific Gemini model.\n",
    "        \"\"\"\n",
    "        print(f\"Initializing with model: {model}\")\n",
    "        self.model = model\n",
    "        self.ignore_patterns = [\n",
    "            '.git', '__pycache__', 'node_modules', 'dist', 'build',\n",
    "            '.DS_Store', '*.pyc', '*.log', '*.tmp', '*.swp'\n",
    "        ]\n",
    "        self.text_file_extensions = [\n",
    "            '.py', '.js', '.ts', '.java', '.c', '.cpp', '.h', '.hpp', '.cs',\n",
    "            '.go', '.rs', '.rb', '.php', '.html', '.css', '.scss', '.json',\n",
    "            '.xml', '.yaml', '.yml', '.md', '.txt', '.sh', '.toml', '.ini',\n",
    "            'Dockerfile', 'Makefile'\n",
    "        ]\n",
    "\n",
    "\n",
    "    def _is_text_file(self, file_path):\n",
    "        \"\"\"Checks if a file is likely a text file based on its extension.\"\"\"\n",
    "        return any(file_path.name.endswith(ext) for ext in self.text_file_extensions)\n",
    "\n",
    "\n",
    "    def _get_repo_structure(self, repo_path):\n",
    "        \"\"\"\n",
    "        Creates a string representation of the repository's file structure.\n",
    "        \"\"\"\n",
    "        tree_str = \"\"\n",
    "        for root, dirs, files in os.walk(repo_path):\n",
    "            # Filter out ignored directories\n",
    "            dirs[:] = [d for d in dirs if d not in self.ignore_patterns]\n",
    "            \n",
    "            level = root.replace(repo_path, '').count(os.sep)\n",
    "            indent = ' ' * 4 * level\n",
    "            tree_str += f\"{indent}ðŸ“ {os.path.basename(root)}/\\n\"\n",
    "            \n",
    "            sub_indent = ' ' * 4 * (level + 1)\n",
    "            for f in files:\n",
    "                if f not in self.ignore_patterns:\n",
    "                    tree_str += f\"{sub_indent}ðŸ“„ {f}\\n\"\n",
    "        return tree_str\n",
    "\n",
    "\n",
    "    def _get_dependencies(self, repo_path):\n",
    "        \"\"\"\n",
    "        Finds and reads common dependency files.\n",
    "        \"\"\"\n",
    "        dependency_files = {\n",
    "            \"Python\": \"requirements.txt\",\n",
    "            \"Node.js\": \"package.json\",\n",
    "            \"Java (Maven)\": \"pom.xml\",\n",
    "            \"Java (Gradle)\": \"build.gradle\",\n",
    "            \"Ruby\": \"Gemfile\",\n",
    "        }\n",
    "        found_deps = \"No common dependency files found.\"\n",
    "        for tech, filename in dependency_files.items():\n",
    "            path = Path(repo_path) / filename\n",
    "            if path.exists():\n",
    "                try:\n",
    "                    found_deps = f\"--- {tech} Dependencies ({filename}) ---\\n\"\n",
    "                    found_deps += path.read_text(encoding='utf-8') + \"\\n\\n\"\n",
    "                except Exception as e:\n",
    "                    found_deps += f\"Could not read {filename}: {e}\\n\\n\"\n",
    "        return found_deps\n",
    "\n",
    "\n",
    "    def _summarize_key_files(self, repo_path, num_files=5):\n",
    "        \"\"\"\n",
    "        Finds the largest text files and generates a summary for each.\n",
    "        \"\"\"\n",
    "        file_sizes = []\n",
    "        for root, _, files in os.walk(repo_path):\n",
    "            if any(part in root for part in self.ignore_patterns):\n",
    "                continue\n",
    "            for file in files:\n",
    "                file_path = Path(root) / file\n",
    "                if self._is_text_file(file_path):\n",
    "                    try:\n",
    "                        size = file_path.stat().st_size\n",
    "                        if size > 100: # Ignore very small files\n",
    "                            file_sizes.append((file_path, size))\n",
    "                    except FileNotFoundError:\n",
    "                        continue\n",
    "\n",
    "        # Sort files by size in descending order and get the top N\n",
    "        file_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "        key_files = [f[0] for f in file_sizes[:num_files]]\n",
    "\n",
    "        print(f\"\\nSummarizing the {len(key_files)} largest files...\")\n",
    "        summaries = []\n",
    "        for file_path in key_files:\n",
    "            relative_path = file_path.relative_to(repo_path)\n",
    "            print(f\"  - Reading: {relative_path}\")\n",
    "            try:\n",
    "                content = file_path.read_text(encoding='utf-8')\n",
    "                if len(content.strip()) == 0:\n",
    "                    continue\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "                Analyze the following code from the file '{relative_path}'.\n",
    "                Provide a concise, high-level summary (2-3 sentences) of its purpose and key functionality.\n",
    "\n",
    "                ```\n",
    "                {content[:4000]}\n",
    "                ```\n",
    "                \"\"\"\n",
    "                response = self.model.generate_content(prompt)\n",
    "                summaries.append(f\"ðŸ“„ **File: {relative_path}**\\n{response.text}\\n\")\n",
    "            except Exception as e:\n",
    "                summaries.append(f\"ðŸ“„ **File: {relative_path}**\\n   - Could not summarize: {e}\\n\")\n",
    "\n",
    "        return \"\\n\".join(summaries)\n",
    "\n",
    "\n",
    "    def summarize_repo(self, repo_path: str, feedback: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Summarizes a repository from a local path, using optional feedback to improve accuracy.\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(repo_path):\n",
    "            return \"Error: Provided repository path is not a directory.\"\n",
    "\n",
    "        # Add a header for regeneration attempts\n",
    "        if feedback:\n",
    "            print(\"\\nRe-generating summary with feedback...\")\n",
    "        else:\n",
    "            print(\"\\nAnalyzing repository structure...\")\n",
    "        \n",
    "        structure = self._get_repo_structure(repo_path)\n",
    "        dependencies = self._get_dependencies(repo_path)\n",
    "        file_summaries = self._summarize_key_files(repo_path)\n",
    "\n",
    "        feedback_prompt_section = \"\"\n",
    "        if feedback:\n",
    "            feedback_prompt_section = f\"\"\"\n",
    "            --- PREVIOUS ATTEMPT FEEDBACK ---\n",
    "            A previous attempt to summarize this repository was found to be inaccurate.\n",
    "            Use the following feedback to create a new, more accurate summary.\n",
    "            Do not repeat the previous mistakes.\n",
    "\n",
    "            Feedback: {feedback}\n",
    "            ---\n",
    "            \"\"\"\n",
    "\n",
    "        final_prompt = f\"\"\"\n",
    "        You are a senior software architect...\n",
    "        Based on the information provided below, generate a comprehensive, high-level summary.\n",
    "        {feedback_prompt_section}\n",
    "        --- REPOSITORY INFORMATION ---\n",
    "        **1. File & Directory Structure:**\n",
    "        ```\n",
    "        {structure[:4000]}\n",
    "        ```\n",
    "        **2. Detected Dependencies:**\n",
    "        ```\n",
    "        {dependencies}\n",
    "        ```\n",
    "        **3. Summaries of Key Files:**\n",
    "        ```\n",
    "        {file_summaries}\n",
    "        ```\n",
    "        --- END OF INFORMATION ---\n",
    "        Provide the final summary in a clear, well-structured markdown format.\n",
    "        \"\"\"\n",
    "        final_response = self.model.generate_content(final_prompt)\n",
    "        return final_response.text\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e71ca137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning https://github.com/sismics/music.git into temporary directory ../temp...\n",
      "Cloning successful.\n",
      "Initializing with model: genai.GenerativeModel(\n",
      "    model_name='models/gemini-2.5-flash',\n",
      "    generation_config={},\n",
      "    safety_settings={},\n",
      "    tools=None,\n",
      "    system_instruction=None,\n",
      "    cached_content=None\n",
      ")\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Looking for dependency files...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: music-web\\src\\main\\webapp\\src\\lib\\angular.js\n",
      "  - Reading: music-web\\src\\main\\webapp\\src\\lib\\less.js\n",
      "  - Reading: music-web\\src\\main\\webapp\\src\\lib\\jquery.js\n",
      "  - Reading: music-web\\src\\main\\webapp\\src\\lib\\angular.ui-bootstrap.js\n",
      "  - Reading: music-web\\src\\main\\webapp\\src\\style\\bootstrap.css\n",
      "\n",
      "Generating final high-level summary...\n",
      "\n",
      "Cleaning up temporary directory: ../temp\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: '../temp\\\\.git\\\\objects\\\\pack\\\\pack-d241ba789be9fd46690571af2fa6ad1147354153.idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m repo_path \u001b[38;5;241m=\u001b[39m _clone_repo(repo_url_to_summarize)\n\u001b[0;32m     16\u001b[0m summarizer_agent \u001b[38;5;241m=\u001b[39m RepoSummarizer(model\u001b[38;5;241m=\u001b[39mllm_model)\n\u001b[1;32m---> 17\u001b[0m summary \u001b[38;5;241m=\u001b[39m summarizer_agent\u001b[38;5;241m.\u001b[39msummarize_repo(repo_path)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ FINAL REPOSITORY SUMMARY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 172\u001b[0m, in \u001b[0;36mRepoSummarizer.summarize_repo\u001b[1;34m(self, repo_path)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Clean up the temporary directory\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCleaning up temporary directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m shutil\u001b[38;5;241m.\u001b[39mrmtree(repo_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\shutil.py:781\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;66;03m# can't continue even if onexc hook returns\u001b[39;00m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _rmtree_unsafe(path, onexc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\shutil.py:635\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onexc)\u001b[0m\n\u001b[0;32m    633\u001b[0m             os\u001b[38;5;241m.\u001b[39munlink(fullname)\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 635\u001b[0m             onexc(os\u001b[38;5;241m.\u001b[39munlink, fullname, err)\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    637\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\shutil.py:633\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onexc)\u001b[0m\n\u001b[0;32m    631\u001b[0m fullname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, name)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 633\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(fullname)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    635\u001b[0m     onexc(os\u001b[38;5;241m.\u001b[39munlink, fullname, err)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: '../temp\\\\.git\\\\objects\\\\pack\\\\pack-d241ba789be9fd46690571af2fa6ad1147354153.idx'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# A simple, well-known Python repository\n",
    "# repo_url_to_summarize = \"https://github.com/requests/requests.git\"\n",
    "\n",
    "# A more complex JavaScript repository\n",
    "# repo_url_to_summarize = \"https://github.com/axios/axios.git\"\n",
    "\n",
    "# A Go repository\n",
    "# repo_url_to_summarize = \"https://github.com/gin-gonic/gin.git\"\n",
    "\n",
    "llm_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "\n",
    "# Sismics music\n",
    "repo_url_to_summarize = \"https://github.com/sismics/music.git\"\n",
    "repo_path = _clone_repo(repo_url_to_summarize)\n",
    "summarizer_agent = RepoSummarizer(model=llm_model)\n",
    "summary = summarizer_agent.summarize_repo(repo_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸš€ FINAL REPOSITORY SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee711f8",
   "metadata": {},
   "source": [
    "### SummaryChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9067a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryCheckerAgent:\n",
    "    \"\"\"\n",
    "    Verifies a summary and provides actionable feedback for correction if it's inaccurate.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: genai.GenerativeModel):\n",
    "        print(\"Initializing SummaryCheckerAgent...\")\n",
    "        self.model = model\n",
    "\n",
    "    def verify_summary(self, summary: str, repo_path: str) -> (bool, str):\n",
    "        \"\"\"\n",
    "        Verifies the summary and generates corrective feedback if needed.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - A boolean: True if the summary is correct, False otherwise.\n",
    "            - A string: A justification if correct, or actionable feedback if incorrect.\n",
    "        \"\"\"\n",
    "        print(f\"Verifying summary against the code in {repo_path}...\")\n",
    "        tree_str = \"\"\n",
    "        # (The logic to get tree_str remains the same as before)\n",
    "        for root, dirs, files in os.walk(repo_path):\n",
    "            dirs[:] = [d for d in dirs if d not in ['.git', 'node_modules']]\n",
    "            level = root.replace(repo_path, '').count(os.sep)\n",
    "            indent = ' ' * 4 * level\n",
    "            tree_str += f\"{indent}{os.path.basename(root)}/\\n\"\n",
    "            sub_indent = ' ' * 4 * (level + 1)\n",
    "            for f in files:\n",
    "                tree_str += f\"{sub_indent}{f}\\n\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a meticulous code reviewer. Your task is to determine if the given **Summary**\n",
    "        accurately reflects the provided **Repository Context**.\n",
    "\n",
    "        **Repository Context (File and Directory Structure):**\n",
    "        ---\n",
    "        {tree_str[:4000]}\n",
    "        ---\n",
    "\n",
    "        **Summary to Verify:**\n",
    "        ---\n",
    "        {summary}\n",
    "        ---\n",
    "\n",
    "        First, provide your verdict as a single word: **CORRECT** or **INCORRECT**.\n",
    "        - If the verdict is **CORRECT**, follow it with a colon and a brief justification.\n",
    "        - If the verdict is **INCORRECT**, follow it with a colon and then, on a new line, provide actionable **FEEDBACK** for the summarizer agent on how to fix the summary. This feedback should be a clear instruction.\n",
    "\n",
    "        Example CORRECT response:\n",
    "        CORRECT: The summary accurately identifies this as a Java project.\n",
    "\n",
    "        Example INCORRECT response:\n",
    "        INCORRECT: The summary incorrectly identifies this as a Python project.\n",
    "        FEEDBACK: The repository contains `pom.xml` and Java source files, not Python files. Please regenerate the summary identifying the project as a Java Maven application.\n",
    "        \"\"\"\n",
    "        response = self.model.generate_content(prompt)\n",
    "        result_text = response.text.strip()\n",
    "        \n",
    "        is_correct = result_text.startswith(\"CORRECT\")\n",
    "        feedback = result_text\n",
    "\n",
    "        if is_correct:\n",
    "            print(f\"-> Verification Result: CORRECT\")\n",
    "        else:\n",
    "            print(f\"-> Verification Result: INCORRECT\")\n",
    "        \n",
    "        return is_correct, feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cff43a3",
   "metadata": {},
   "source": [
    "### AdrWriterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93ced37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Model for an ADR ---\n",
    "class ADR(BaseModel):\n",
    "    \"\"\"Represents a single Architecture Decision Record.\"\"\"\n",
    "    title: str\n",
    "    context: str\n",
    "    decision: str\n",
    "    # Accept either a simple string or a structured dictionary for consequences\n",
    "    consequences: Union[str, Dict[str, List[str]]]\n",
    "\n",
    "# --- ADR Writer Agent ---\n",
    "class AdrWriterAgent:\n",
    "    \"\"\"\n",
    "    An agent that analyzes a repository summary to identify, format,\n",
    "    and save key design decisions as Architecture Decision Records (ADRs).\n",
    "    \"\"\"\n",
    "    def __init__(self, model: genai.GenerativeModel):\n",
    "        \"\"\"\n",
    "        Initializes the AdrWriterAgent.\n",
    "\n",
    "        Args:\n",
    "            model: An initialized generative model instance.\n",
    "        \"\"\"\n",
    "        print(\"Initializing AdrWriterAgent...\")\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def _extract_design_decisions(self, summary: str, feedback: str = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Uses the LLM to extract design decisions, with a more robust prompt.\n",
    "        \"\"\"\n",
    "        if feedback:\n",
    "            print(\"Re-extracting design decisions with new feedback...\")\n",
    "        else:\n",
    "            print(\"Extracting design decisions from the summary...\")\n",
    "\n",
    "        feedback_prompt_section = \"\"\n",
    "        if feedback:\n",
    "            feedback_prompt_section = f\"\"\"\n",
    "            --- PREVIOUS ATTEMPT FEEDBACK ---\n",
    "            A previous attempt to generate ADRs was found to be inaccurate.\n",
    "            Use the following feedback to create a new, more accurate set of ADRs based on the summary.\n",
    "\n",
    "            Feedback: {feedback}\n",
    "            ---\n",
    "            \"\"\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert senior software architect. Your task is to analyze the provided repository summary\n",
    "        and extract the most critical architectural and technological design decisions.\n",
    "        {feedback_prompt_section}\n",
    "        **Repository Summary**:\n",
    "        ---\n",
    "        {summary}\n",
    "        ---\n",
    "\n",
    "        Return your response as a valid JSON array of objects.\n",
    "        **It is critical that each object in the array has the following four string keys exactly as written: `title`, `context`, `decision`, `consequences`.**\n",
    "        \n",
    "        Do not use any other key names. For example, do not use `decision_point` instead of `title`. The format must be strictly followed.\n",
    "        \"\"\"\n",
    "        response = self.model.generate_content(prompt)\n",
    "        clean_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        try:\n",
    "            decisions = json.loads(clean_response)\n",
    "            print(f\"Successfully extracted {len(decisions)} design decisions.\")\n",
    "            return decisions\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: The model did not return a valid JSON. Raw response:\\n{clean_response}\")\n",
    "            # Return an empty list to prevent crashes, allowing the feedback loop to potentially correct it.\n",
    "            return []\n",
    "\n",
    "    def _format_adrs(self, adrs: List[ADR]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Formats a list of ADR objects into a list of markdown strings.\n",
    "        This method NO LONGER saves files.\n",
    "        \"\"\"\n",
    "        if not adrs:\n",
    "            return []\n",
    "\n",
    "        formatted_adrs_list = []\n",
    "        for i, adr in enumerate(adrs, start=1):\n",
    "            consequences_text = \"\"\n",
    "            if isinstance(adr.consequences, dict):\n",
    "                pros = adr.consequences.get(\"pros\", [])\n",
    "                cons = adr.consequences.get(\"cons\", [])\n",
    "                if pros:\n",
    "                    consequences_text += \"**Pros:**\\n\" + \"\\n\".join(f\"- {item}\" for item in pros) + \"\\n\\n\"\n",
    "                if cons:\n",
    "                    consequences_text += \"**Cons:**\\n\" + \"\\n\".join(f\"- {item}\" for item in cons)\n",
    "            else:\n",
    "                consequences_text = adr.consequences\n",
    "\n",
    "            adr_text = f\"\"\"# ADR-{i:03d}: {adr.title}\n",
    "\n",
    "**Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
    "**Status**: Proposed\n",
    "\n",
    "## Context\n",
    "{adr.context}\n",
    "\n",
    "## Decision\n",
    "{adr.decision}\n",
    "\n",
    "## Consequences\n",
    "{consequences_text.strip()}\n",
    "\"\"\"\n",
    "            formatted_adrs_list.append(adr_text.strip())\n",
    "        \n",
    "        return formatted_adrs_list\n",
    "\n",
    "    def write_adrs(self, summary: str, feedback: str = None) -> (List[ADR], List[str]):\n",
    "        \"\"\"\n",
    "        Main method to generate and format ADRs.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - A list of the structured ADR Pydantic objects.\n",
    "            - A list of the formatted ADR strings.\n",
    "        \"\"\"\n",
    "        decisions_data = self._extract_design_decisions(summary, feedback)\n",
    "        if not decisions_data:\n",
    "            return [], [] # Return empty lists if extraction fails\n",
    "            \n",
    "        adrs = [ADR(**data) for data in decisions_data]\n",
    "        formatted_adrs = self._format_adrs(adrs)\n",
    "        return adrs, formatted_adrs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac3d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AdrWriterAgent...\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 3 design decisions.\n",
      "Saving ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs'\n",
      "  -> Successfully saved 001_Self-Hosted_Multi-Platform_Architecture.md\n",
      "  -> Successfully saved 002_Java_as_Primary_Backend__Desktop_Language.md\n",
      "  -> Successfully saved 003_Embedded_H2_Database_for_Data_Persistence.md\n",
      "Formatting and saving complete.\n",
      "\n",
      "âœ… Process complete. Returned a list with 3 ADRs.\n",
      "You can find the markdown files in the 'Generated_ADRs' folder.\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the model and the agent\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "adr_agent = AdrWriterAgent(model=model)\n",
    "\n",
    "adr_output_directory = \"Generated_ADRs\"\n",
    "\n",
    "# 4. Run the agent's main method\n",
    "list_of_adr_strings = adr_agent.write_and_save_adrs(\n",
    "    summary=summary,\n",
    "    output_path=adr_output_directory\n",
    ")\n",
    "\n",
    "# 5. The results are now in the returned list and saved to disk\n",
    "if list_of_adr_strings:\n",
    "    print(f\"\\nâœ… Process complete. Returned a list with {len(list_of_adr_strings)} ADRs.\")\n",
    "    print(f\"You can find the markdown files in the '{adr_output_directory}' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ecb89",
   "metadata": {},
   "source": [
    "### ADR Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34be7b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdrCheckerAgent:\n",
    "    \"\"\"\n",
    "    Verifies that a list of ADRs is logical, well-formed, and consistent\n",
    "    with the provided repository summary. Provides feedback for correction.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: genai.GenerativeModel):\n",
    "        print(\"Initializing AdrCheckerAgent...\")\n",
    "        self.model = model\n",
    "\n",
    "    def verify_adrs(self, summary: str, adrs: List[str]) -> (bool, str):\n",
    "        \"\"\"\n",
    "        Verifies the ADRs against the repository summary.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - A boolean: True if the ADRs are deemed correct, False otherwise.\n",
    "            - A string: A justification if correct, or actionable feedback if incorrect.\n",
    "        \"\"\"\n",
    "        print(\"Verifying generated ADRs against the summary...\")\n",
    "        # Join the list of ADR strings into a single block for the prompt\n",
    "        adrs_text = \"\\n\\n---\\n\\n\".join(adrs)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a principal software architect reviewing a set of auto-generated\n",
    "        Architecture Decision Records (ADRs). Your task is to ensure the ADRs are logical,\n",
    "        well-written, and directly supported by the provided **Repository Summary**.\n",
    "\n",
    "        **Repository Summary:**\n",
    "        ---\n",
    "        {summary}\n",
    "        ---\n",
    "\n",
    "        **ADRs to Verify:**\n",
    "        ---\n",
    "        {adrs_text}\n",
    "        ---\n",
    "\n",
    "        Analyze the ADRs. Do they capture the most important architectural decisions\n",
    "        mentioned in the summary (e.g., choice of framework, database, architecture pattern)?\n",
    "        Are the 'Context', 'Decision', and 'Consequences' sections plausible for a project\n",
    "        as described in the summary?\n",
    "\n",
    "        Your final answer MUST begin with a single word: **CORRECT** or **INCORRECT**.\n",
    "        - If **CORRECT**, provide a brief justification.\n",
    "        - If **INCORRECT**, provide actionable **FEEDBACK** for the ADR writing agent.\n",
    "\n",
    "        Example CORRECT response:\n",
    "        CORRECT: The ADRs accurately capture the key decisions regarding the multi-module Maven structure and the use of AngularJS on the frontend.\n",
    "\n",
    "        Example INCORRECT response:\n",
    "        INCORRECT: ADR-2, which discusses PostgreSQL, is not supported by the summary that explicitly mentions an H2 embedded database.\n",
    "        FEEDBACK: Please correct ADR-2 to reflect the use of the H2 database as stated in the summary. Additionally, add a new ADR for the decision to use a multi-module Maven monorepo, as this is a key architectural choice mentioned in the summary.\n",
    "        \"\"\"\n",
    "        response = self.model.generate_content(prompt)\n",
    "        result_text = response.text.strip()\n",
    "\n",
    "        is_correct = result_text.startswith(\"CORRECT\")\n",
    "        feedback = result_text\n",
    "\n",
    "        if is_correct:\n",
    "            print(\"-> Verification Result: ADRs are CORRECT\")\n",
    "        else:\n",
    "            print(\"-> Verification Result: ADRs are INCORRECT\")\n",
    "\n",
    "        return is_correct, feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5a21b",
   "metadata": {},
   "source": [
    "### Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b461dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrchestratorAgent:\n",
    "    \"\"\"\n",
    "    Orchestrates the workflow with a self-correcting feedback loop for summarization.\n",
    "    1. Clone a repo.\n",
    "    2. Summarize it.\n",
    "    3. Verify the summary.\n",
    "    4. Generate ADRs from the verified summary.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: genai.GenerativeModel):\n",
    "        print(\"Initializing the Orchestrator Agent...\")\n",
    "        self.summarizer_agent = RepoSummarizer(model=model)\n",
    "        self.summary_checker_agent = SummaryCheckerAgent(model=model)\n",
    "        self.adr_writer_agent = AdrWriterAgent(model=model)\n",
    "        self.adr_checker_agent = AdrCheckerAgent(model=model)\n",
    "        print(\"Orchestrator is ready with all subordinate agents.\")\n",
    "\n",
    "    def _clone_repo(self, repo_url: str) -> str:\n",
    "        \"\"\"\n",
    "        Clones a repository into a temporary directory.\n",
    "        Returns the path to the temporary directory.\n",
    "        \"\"\" \n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        try:\n",
    "            print(f\"Cloning {repo_url} into temporary directory {temp_dir}...\")\n",
    "            subprocess.check_call(['git', 'clone', repo_url, temp_dir], stderr=subprocess.DEVNULL)\n",
    "            print(\"Cloning successful.\")\n",
    "            return temp_dir\n",
    "        except (subprocess.CalledProcessError, FileNotFoundError) as e:\n",
    "            print(f\"Error cloning repository: {e}. Please check the URL and that Git is installed.\")\n",
    "            # Clean up the failed clone attempt\n",
    "            shutil.rmtree(temp_dir)\n",
    "            return None\n",
    "        \n",
    "    def _sanitize_filename(self, name: str) -> str:\n",
    "        \"\"\"\n",
    "        Helper method now owned by the orchestrator.\n",
    "        \"\"\"\n",
    "        name = name.replace(' ', '_')\n",
    "        name = re.sub(r'[^\\w\\.-]', '', name)\n",
    "        return name[:100]\n",
    "\n",
    "    def _save_adrs(self, adrs: List[ADR], formatted_adrs: List[str], output_path: str):\n",
    "        \"\"\"\n",
    "        Saves the final, verified ADRs to disk.\n",
    "        \"\"\"\n",
    "        if not adrs:\n",
    "            print(\"No ADRs to save.\")\n",
    "            return\n",
    "\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        print(f\"Saving final ADRs to directory: '{os.path.abspath(output_path)}'\")\n",
    "\n",
    "        for i, (adr_object, adr_content) in enumerate(zip(adrs, formatted_adrs), start=1):\n",
    "            safe_filename = self._sanitize_filename(adr_object.title)\n",
    "            filename = f\"{i:03d}_{safe_filename}.md\"\n",
    "            file_path = os.path.join(output_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(adr_content)\n",
    "                print(f\"  -> Successfully saved {filename}\")\n",
    "            except IOError as e:\n",
    "                print(f\"  -> Failed to save {filename}. Error: {e}\")\n",
    "\n",
    "    def run(self, repo_url: str, adr_output_path: str, max_attempts: int = 3):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ðŸš€ Starting Orchestration Workflow\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        repo_path = self._clone_repo(repo_url)\n",
    "        if not repo_path: return []\n",
    "\n",
    "        # --- LOOP 1: Summary Generation and Verification ---\n",
    "        summary = \"\"\n",
    "        summary_feedback = None\n",
    "        is_summary_correct = False\n",
    "        for attempt in range(max_attempts):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"ðŸ”¥ Summary Generation Attempt {attempt + 1} of {max_attempts}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            summary = self.summarizer_agent.summarize_repo(repo_path=repo_path, feedback=summary_feedback)\n",
    "            is_summary_correct, summary_feedback = self.summary_checker_agent.verify_summary(summary=summary, repo_path=repo_path)\n",
    "            print(f\"Feedback Received: {summary_feedback}\")\n",
    "\n",
    "            if is_summary_correct:\n",
    "                print(\"\\nâœ… Summary confirmed accurate. Proceeding to ADR generation.\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"\\nâŒ Summary incorrect. Will attempt to regenerate.\")\n",
    "        \n",
    "        # if not is_summary_correct:\n",
    "        #     print(f\"\\nðŸš¨ Workflow Halted: Failed to generate an accurate summary after {max_attempts} attempts.\")\n",
    "        #     return []\n",
    "\n",
    "        # --- LOOP 2: ADR Generation and Verification ---\n",
    "        list_of_adr_objects = []\n",
    "        list_of_adr_strings = []\n",
    "        adr_feedback = None\n",
    "        are_adrs_correct = False\n",
    "        for attempt in range(max_attempts):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"ðŸ”¥ ADR Generation Attempt {attempt + 1} of {max_attempts}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # 1. GENERATE ADRs (content only, no saving yet)\n",
    "            list_of_adr_objects, list_of_adr_strings = self.adr_writer_agent.write_adrs(summary=summary, feedback=adr_feedback)\n",
    "            \n",
    "            # 2. VERIFY the generated ADRs\n",
    "            if not list_of_adr_strings:\n",
    "                print(\"ADR writer returned no content. Continuing attempt.\")\n",
    "                adr_feedback = \"The previous attempt returned no content. Please try again, ensuring you generate valid ADRs from the summary.\"\n",
    "                continue\n",
    "\n",
    "            are_adrs_correct, adr_feedback = self.adr_checker_agent.verify_adrs(summary=summary, adrs=list_of_adr_strings)\n",
    "            print(f\"Feedback Received: {adr_feedback}\")\n",
    "\n",
    "            if are_adrs_correct:\n",
    "                print(\"\\nâœ… ADRs confirmed accurate.\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"\\nâŒ ADRs incorrect. Will attempt to regenerate.\")\n",
    "\n",
    "        # if not are_adrs_correct:\n",
    "        #     print(f\"\\nðŸš¨ Workflow Halted: Failed to generate accurate ADRs after {max_attempts} attempts.\")\n",
    "        #     return []\n",
    "\n",
    "        # --- FINAL STEP: Save the approved ADRs ---\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ðŸ’¾ Saving verified ADRs to disk...\")\n",
    "        self._save_adrs(list_of_adr_objects, list_of_adr_strings, adr_output_path)\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Orchestration Workflow Finished Successfully!\")\n",
    "        print(\"=\"*50)\n",
    "        return list_of_adr_strings\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954a0a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: genai.GenerativeModel(\n",
      "    model_name='models/gemini-2.5-flash',\n",
      "    generation_config={},\n",
      "    safety_settings={},\n",
      "    tools=None,\n",
      "    system_instruction=None,\n",
      "    cached_content=None\n",
      ")\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing AdrCheckerAgent...\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/karthikv1392/cs6401_se.git into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpsr936o19...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: Project\\project_1.md\n",
      "  - Reading: _site\\projects\\project-1.html\n",
      "  - Reading: Project\\project_2.md\n",
      "  - Reading: _layouts\\minimal.html\n",
      "  - Reading: course_policy.md\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpsr936o19...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary makes specific claims about the *content* of certain files (e.g., `course_policy.md`, `Project/project_1.md`), such as details on learning methodology, plagiarism policy, AI tool usage, flexible submission, and specific project topics (RSS reader, music server). However, the \"Repository Context\" provided is strictly the file and directory structure, not the content of individual files. These claims cannot be verified from the given context.\n",
      "FEEDBACK: Please revise the summary to only include observations and inferences that can be directly supported by the *file and directory structure* provided in the Repository Context. Do not make claims about the specific textual content of files unless that content is explicitly included in the context.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: Project\\project_1.md\n",
      "  - Reading: _site\\projects\\project-1.html\n",
      "  - Reading: Project\\project_2.md\n",
      "  - Reading: _layouts\\minimal.html\n",
      "  - Reading: course_policy.md\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpsr936o19...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary meticulously details the repository's structure and contents, accurately identifying it as a Jekyll-based academic course website. It correctly lists key components like lectures, slides, projects, tutorials, modules, announcements, calendar, policy, and staff, and accurately describes the Jekyll implementation details. The \"Key Observation\" section also demonstrates a thorough review by highlighting a potential content inconsistency between source and generated files, which is an excellent addition.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 5 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs accurately capture the key architectural decisions regarding the choice of Jekyll and GitHub Pages, structured content management, custom front-end design, and relevant pedagogical and policy decisions that define the course website's structure and functionality. The 'Context', 'Decision', and 'Consequences' sections for each ADR are well-supported by the repository summary, with particular credit for incorporating the \"Key Observation\" about the Project 1 discrepancy into the negative consequences of ADR-002 and ADR-004.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\karthikv1392_cs6401_se'\n",
      "  -> Successfully saved 001_Adoption_of_Jekyll_for_Static_Site_Generation_with_GitHub_Pages_Deployment.md\n",
      "  -> Successfully saved 002_Structured_Content_Management_using_Markdown_Jekyll_Collections_and_Hierarchical_Directories.md\n",
      "  -> Successfully saved 003_Custom_Front-End_Design_and_Theming_for_Enhanced_User_Experience.md\n",
      "  -> Successfully saved 004_Pedagogical_Design_Centered_on_Practical_Multi-Phase_Software_Engineering_Projects.md\n",
      "  -> Successfully saved 005_Design_of_a_Comprehensive_and_Adaptive_Course_Policy_Framework.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete. 5 ADRs were generated and saved.\n",
      "You can find the markdown files in the 'Generated_ADRs/karthikv1392_cs6401_se' folder.\n"
     ]
    }
   ],
   "source": [
    "# --- EXAMPLE USAGE OF THE ORCHESTRATOR ---\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Define your inputs\n",
    "    # repo_url_to_process = \"https://github.com/sismics/music.git\"\n",
    "    repo_url_to_process = \"https://github.com/karthikv1392/cs6401_se.git\"\n",
    "    output_directory_for_adrs = 'Generated_ADRs/' + repo_url_to_process[19:].removesuffix('.git').replace('/', '_')\n",
    "    # output_directory_for_adrs = \"Generated_ADRs/Agentic\"\n",
    "\n",
    "    llm_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator = OrchestratorAgent(model=llm_model)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs\n",
    "    )\n",
    "\n",
    "    # Final confirmation\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete. {len(final_adrs)} ADRs were generated and saved.\")\n",
    "        print(f\"You can find the markdown files in the '{output_directory_for_adrs}' folder.\")\n",
    "    else:\n",
    "        print(\"\\nProcess finished, but no ADRs were generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266581c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
