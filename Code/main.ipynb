{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f01a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LAB\\ADR\\AgenticAdr\n"
     ]
    }
   ],
   "source": [
    "cd D:\\LAB\\ADR\\AgenticAdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a47523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.AdrAgents import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72638812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adrs(repo_url_to_process):\n",
    "    output_directory_for_adrs = 'Generated_ADRs/' + repo_url_to_process[19:].removesuffix('.git').replace('/', '_')\n",
    "\n",
    "    output_directory_for_adrs_gimini = output_directory_for_adrs + '/dir3'\n",
    "    model_name = \"gemini-2.5-pro\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gimini = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gimini.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gimini,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gimini. {len(final_adrs)} ADRs were generated and saved.\")\n",
    "\n",
    "    output_directory_for_adrs_gpt = output_directory_for_adrs + '/dir4'\n",
    "    model_name = \"gpt-5\"\n",
    "\n",
    "    # Instantiate the Orchestrator Agent\n",
    "    orchestrator_gpt = OrchestratorAgent(model_name=model_name)\n",
    "\n",
    "    # Execute the entire workflow with a single call\n",
    "    final_adrs = orchestrator_gpt.run(\n",
    "        repo_url=repo_url_to_process,\n",
    "        adr_output_path=output_directory_for_adrs_gpt,\n",
    "        max_attempts=3\n",
    "    )\n",
    "\n",
    "    if final_adrs:\n",
    "        print(f\"\\nProcess complete with Gpt. {len(final_adrs)} ADRs were generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/Poorvi-HC/DIP-Project into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpr89guxdn...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: extract_features.py\n",
      "  - Reading: algorithm3.py\n",
      "  - Reading: algorithm2.py\n",
      "  - Reading: algorithm1.py\n",
      "  - Reading: algorithm4.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpr89guxdn...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately deduces the project's purpose, architecture, and technology stack from the file names. It correctly identifies the roles of key files like `extract_features.py`, `svm_train.py`, and the set of `algorithm*.py` scripts, and makes reasonable, well-supported inferences about the specific techniques being used.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 5 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a high-quality and accurate representation of the architecture described in the repository summary. They correctly identify and articulate the most significant architectural decisions, including the decoupled feature extraction pipeline, the multi-algorithm testbed structure, the mix of classical and ML approaches, the separation of ML training from inference, and the use of keypoint descriptors. Each ADR is logical, well-written, and its claims are directly supported by the provided summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\Poorvi-HC_DIP-Project\\dir3'\n",
      "  -> Successfully saved 001_Decoupled_Feature_Extraction_and_Sequence_Reconstruction_Pipeline.md\n",
      "  -> Successfully saved 002_Multi-Algorithm_Architecture_for_Comparative_Analysis.md\n",
      "  -> Successfully saved 003_Inclusion_of_Both_Classical_and_Machine_Learning-Based_Solvers.md\n",
      "  -> Successfully saved 004_Separation_of_ML_Model_Training_from_Inference.md\n",
      "  -> Successfully saved 005_Use_of_Keypoint_Descriptors_SIFTORB_for_Frame_Representation.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 5 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/Poorvi-HC/DIP-Project into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpva49zplr...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: extract_features.py\n",
      "  - Reading: algorithm3.py\n",
      "  - Reading: algorithm2.py\n",
      "  - Reading: algorithm1.py\n",
      "  - Reading: algorithm4.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpva49zplr...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary omits algorithm5.py and asserts specific implementation details (e.g., SIFT/ORB usage, BFMatcher, custom cv2.KeyPoint pickling, algorithm4â€™s SVM coupling, grayscale triplication) that arenâ€™t supported by the provided repository context.\n",
      "\n",
      "FEEDBACK: Revise the summary to (1) include and accurately describe algorithm5.py, (2) verify from the code which feature detectors/descriptors and matchers are actually used in extract_features.py and algorithms 1â€“5 (avoid assuming SIFT/ORB or custom pickling unless present), (3) confirm whether svm_train.py and linear_reg_train.py are used by specific algorithms and reflect that linkage correctly, and (4) align inputs/outputs and usage details with README.md rather than speculation.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: extract_features.py\n",
      "  - Reading: algorithm3.py\n",
      "  - Reading: algorithm2.py\n",
      "  - Reading: algorithm1.py\n",
      "  - Reading: algorithm4.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpva49zplr...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary aligns with the repositoryâ€™s Python files and structure: five algorithm scripts, feature extraction, a shuffle utility, helper functions, SVM/linear regression training scripts, a README, and a reportâ€”all consistent with a video frame reordering project.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summaryâ€™s architecture: a staged, file-backed pipeline; centralized feature extraction shared by algorithms; multiple interchangeable reconstruction strategies; optional model-based scoring with heuristic fallback; classical ML training utilities; shared candidate selection utility; preserved ground-truth mapping; CLI/file-path-driven configs; embedded evaluation/visualization; README-governed artifact contracts; algorithmic diversity; and precompute-and-reuse. Context, Decisions, and Consequences are plausible and directly supported by the summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\Poorvi-HC_DIP-Project\\dir4'\n",
      "  -> Successfully saved 001_Stage-based_file-backed_pipeline.md\n",
      "  -> Successfully saved 002_Single_shared_feature_representation_for_all_algorithms.md\n",
      "  -> Successfully saved 003_Multiple_interchangeable_reconstruction_strategies.md\n",
      "  -> Successfully saved 004_Pluggable_learned_scoring_with_heuristic_fallback.md\n",
      "  -> Successfully saved 005_Classical_ML_models_over_end-to-end_learning.md\n",
      "  -> Successfully saved 006_Shared_candidate_selection_utility.md\n",
      "  -> Successfully saved 007_Ground-truth_mapping_preserved_for_evaluation.md\n",
      "  -> Successfully saved 008_CLI-first_file-path-driven_configuration.md\n",
      "  -> Successfully saved 009_Embedded_evaluation_and_visualization_in_algorithm_scripts.md\n",
      "  -> Successfully saved 010_Canonical_artifact_locations_and_schemas_governed_by_README.md\n",
      "  -> Successfully saved 011_Algorithmic_diversity_to_mitigate_strategy_risk.md\n",
      "  -> Successfully saved 012_Precompute-and-reuse_design_for_scalability.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/RL_project into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpy2gkw033...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: SAC.py\n",
      "  - Reading: DQN.py\n",
      "  - Reading: VPG-continuous.py\n",
      "  - Reading: VPG-discrete.py\n",
      "  - Reading: DDPG.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpy2gkw033...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary provides a comprehensive and accurate analysis of the repository. It correctly identifies the project's purpose (RL for stock trading), the specific algorithms implemented, the dual-framework architecture (PyTorch and TensorFlow/Keras), and the overall project structure. The inferences about the functionality of files like `env.py` and the workflow for experimentation are well-supported by the repository context.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 6 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are excellent. They accurately capture and articulate all the key architectural decisions, strengths, and weaknesses identified in the repository summary. Each ADR's Context, Decision, and Consequences are logical, plausible, and directly supported by the provided text.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_RL_project\\dir3'\n",
      "  -> Successfully saved 001_Hybrid_Deep_Learning_Framework_Strategy.md\n",
      "  -> Successfully saved 002_Development_of_a_Custom_Financial_Trading_Environment.md\n",
      "  -> Successfully saved 003_Adoption_of_a_Loosely-Coupled_Script-Based_Architecture.md\n",
      "  -> Successfully saved 004_Implementation_of_a_Diverse_Range_of_RL_Algorithms.md\n",
      "  -> Successfully saved 005_Systematic_Experiment_Tracking_via_TensorBoard_Logging.md\n",
      "  -> Successfully saved 006_Hardcoded_In-Script_Configuration_Management.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 6 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/RL_project into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmplvmutf6m...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: SAC.py\n",
      "  - Reading: DQN.py\n",
      "  - Reading: VPG-continuous.py\n",
      "  - Reading: VPG-discrete.py\n",
      "  - Reading: DDPG.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmplvmutf6m...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary includes several speculative details (e.g., exact environment action bounds/normalization, dependencies like gym-trading-env/Flask/W&B, missing packages in requirements, and SAC/DDPG implementation specifics) that are not verifiable from the provided repository structure alone.\n",
      "\n",
      "FEEDBACK: Regenerate the summary using only what is directly supported by the repository structure. \n",
      "- State that the repo contains RL algorithms (SAC, DDPG, DQN, VPG continuous/discrete) with a custom environment (env.py), stock CSV data (IBM, KO, PEP, WBA), saved models (.pth and a TensorFlow SavedModel), and extensive TensorBoard logs (including KO_PEP runs and Hopper-v4 SAC checkpoints). \n",
      "- Note that both PyTorch (.pth) and TensorFlow (SavedModel) artifacts are present, indicating mixed frameworks, but do not assert which files use which framework unless visible in file contents.\n",
      "- Avoid unverified claims about environment design (action ranges, normalization, reward components), external dependencies (gym-trading-env, Flask, aiohttp/ccxt, W&B), or missing packages in requirements.txt. \n",
      "- Do not infer implementation details like auto-entropy tuning, OU noise, or training completeness without code evidence. \n",
      "- Keep recommendations high-level and tied to observable artifacts (e.g., suggest aligning frameworks, documenting requirements, and describing the custom env in README).\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: SAC.py\n",
      "  - Reading: DQN.py\n",
      "  - Reading: VPG-continuous.py\n",
      "  - Reading: VPG-discrete.py\n",
      "  - Reading: DDPG.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmplvmutf6m...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary includes unsupported specifics about implementation details and dependencies.\n",
      "FEEDBACK: Remove unverified claims that DQN.py is Keras-based and avoid listing specific packages from requirements.txt without examining its contents. Instead, state that TensorFlow usage is evidenced by the SavedModel directory and that requirements.txt is present. Keep the framework note general (mixed PyTorch/TensorFlow) and frame trading/portfolio focus as an inference from the data and logs rather than a definitive statement unless verified from code or README.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 3 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: SAC.py\n",
      "  - Reading: DQN.py\n",
      "  - Reading: VPG-continuous.py\n",
      "  - Reading: VPG-discrete.py\n",
      "  - Reading: DDPG.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmplvmutf6m...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary speculates about the exact contents of requirements.txt (e.g., â€œincludes Gymnasium and gym-trading-envâ€) without evidence in the provided context.\n",
      "\n",
      "FEEDBACK: Revise the summary to avoid asserting specific packages in requirements.txt; state only that requirements.txt exists. Explicitly note the presence of both PyTorch (.pth files) and a TensorFlow SavedModel directory (saved_model.pb) indicating mixed frameworks. Keep the trading/portfolio and Hopper-v4 inferences but frame them as evidence-based (from data files, log names, and model filenames) rather than guaranteed.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summary, covering per-algorithm scripts, a Gymnasium-aligned custom trading environment, dual-domain experiments (finance and Hopper-v4), split VPG implementations by action space, TensorBoard-centric logging with CSV summaries, .pth model checkpointing, ticker-specific CSV data, run-nameâ€“based organization, a lightweight evaluation script, implicit/unpinned DL dependencies, manual hyperparameter variation, and a single-repo RL sandbox. The contexts, decisions, and consequences are plausible and directly supported by the provided evidence, with no contradictory claims.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_RL_project\\dir4'\n",
      "  -> Successfully saved 001_Per-algorithm_monolithic_training_scripts.md\n",
      "  -> Successfully saved 002_Custom_trading_environment_aligned_to_Gymnasium.md\n",
      "  -> Successfully saved 003_Dual-domain_experimentation_strategy.md\n",
      "  -> Successfully saved 004_Split_VPG_implementations_by_action_space.md\n",
      "  -> Successfully saved 005_TensorBoard-first_experiment_logging.md\n",
      "  -> Successfully saved 006_Model_checkpointing_with_.pth_artifacts.md\n",
      "  -> Successfully saved 007_Ticker-specific_CSV-driven_market_data.md\n",
      "  -> Successfully saved 008_Experiment_organization_via_run_naming_conventions.md\n",
      "  -> Successfully saved 009_Minimal_evaluation_harness.md\n",
      "  -> Successfully saved 010_Implicit_deep_learning_framework_dependency.md\n",
      "  -> Successfully saved 011_Manual_hyperparameter_and_architecture_variation.md\n",
      "  -> Successfully saved 012_Single_repository_as_RL_sandbox.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/Shravana into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp8ywk1075...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: shravana-app\\package-lock.json\n",
      "  - Reading: whatsapp-bot\\meta\\utils.py\n",
      "  - Reading: whatsapp-bot\\openai\\service.py\n",
      "  - Reading: whatsapp-bot\\meta\\webhook.py\n",
      "  - Reading: asr.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp8ywk1075...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT:\n",
      "FEEDBACK: The summary makes specific, unverifiable claims about the technologies used. For example, there is no evidence in the file list to confirm the use of \"Bhashini ASR API,\" \"Flask,\" \"Material UI,\" or \"NativeBase.\" While these are plausible technologies for this type of application, the summary should only state what can be directly concluded from the repository context. Please regenerate the summary, either removing claims about specific third-party libraries and APIs or qualifying them as likely inferences rather than established facts.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: shravana-app\\package-lock.json\n",
      "  - Reading: whatsapp-bot\\meta\\utils.py\n",
      "  - Reading: whatsapp-bot\\openai\\service.py\n",
      "  - Reading: whatsapp-bot\\meta\\webhook.py\n",
      "  - Reading: asr.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp8ywk1075...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the provided repository structure, correctly identifying the three main components (React Native app, Python WhatsApp bot, ASR script) and their respective technologies and functionalities based on the file and directory names.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 4 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a logical and accurate representation of the architectural decisions described in the repository summary. Each ADR is directly supported by specific details mentioned in the summary, covering the dual-interface strategy (ADR-001), the use of the OpenAI Assistants API (ADR-002), the integration of the Bhashini ASR service (ADR-003), and the choice of React Native with Expo (ADR-004). The \"Consequences\" sections for each are plausible and demonstrate a good understanding of the trade-offs involved.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_Shravana\\dir3'\n",
      "  -> Successfully saved 001_Dual-Interface_Strategy_for_User_Access.md\n",
      "  -> Successfully saved 002_Managed_Service_for_Stateful_Conversational_AI.md\n",
      "  -> Successfully saved 003_Voice-First_Capability_via_a_Specialized_ASR_Service.md\n",
      "  -> Successfully saved 004_Cross-Platform_Mobile_Development_Framework.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 4 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/Shravana into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpkqvlmut8...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: shravana-app\\package-lock.json\n",
      "  - Reading: whatsapp-bot\\meta\\utils.py\n",
      "  - Reading: whatsapp-bot\\openai\\service.py\n",
      "  - Reading: whatsapp-bot\\meta\\webhook.py\n",
      "  - Reading: asr.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpkqvlmut8...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary makes several specific claims that arenâ€™t supported by the repository structure and likely conflict with the code.\n",
      "\n",
      "FEEDBACK: \n",
      "- Replace the â€œPython shelveâ€ claim with the actual persistence setup: whatsapp-bot includes db.py and schema.sql, and the top-level threads_db appears to be a SQLite database file, not a shelve store. Describe the DB accordingly.\n",
      "- Verify and accurately describe openai/service.py: confirm whether it uses the OpenAI Assistants API with threads/runs versus Chat Completions, and whether it reuses or always creates new threads. Reflect the real behavior and any use of the DB layer (db.py).\n",
      "- Re-check asr.py: confirm the ASR backend. Only state Bhashini/Dhruva integration if the code actually calls those APIs; otherwise describe the real engine (e.g., Whisper/local/other) and supported formats.\n",
      "- Confirm utils.py capabilities: only claim audio transcription via Google SpeechRecognition if that library is present in requirements and implemented in utils.py; otherwise remove or adjust.\n",
      "- Avoid asserting specific RN/Expo versions or libraries (e.g., RN 0.73, Expo SDK 50, Jest) unless verified from package.json; keep the mobile app description to whatâ€™s evident (Expo app with Delivery/HealthCare/Retail screens and tabbed navigation).\n",
      "- Keep security/webhook details grounded in the code: mention the webhook endpoint in meta/webhook.py and signature verification decorator if present, but donâ€™t overstate Graph API utilities/error handling without evidence.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: shravana-app\\package-lock.json\n",
      "  - Reading: whatsapp-bot\\meta\\utils.py\n",
      "  - Reading: whatsapp-bot\\openai\\service.py\n",
      "  - Reading: whatsapp-bot\\meta\\webhook.py\n",
      "  - Reading: asr.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpkqvlmut8...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary aligns with the repositoryâ€™s structure and filenames, accurately describing two main parts (a Python WhatsApp bot and an Expo/React Native app), the presence of webhook, utils, OpenAI service, DB/schema modules, a standalone ASR script with sample OGG files, and a SQLite-backed persistence file (threads_db). The described high-level flows and responsibilities are consistent with the layout.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summary and cover the key decisions: split architecture, Flask webhook with verification, signature validation, SQLite persistence, OpenAI Assistants threads/runs with optional per-user thread reuse, centralized Graph API utils, standalone ASR script, environment-based config, hosting assumptions, and mobile app decoupling. The Context/Decision/Consequences sections are plausible and consistent with the described code and operational constraints.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_Shravana\\dir4'\n",
      "  -> Successfully saved 001_Split_architecture_WhatsApp_bot_backend_and_ExpoReact_Native_app_are_independent.md\n",
      "  -> Successfully saved 002_Flask-based_webhook_for_WhatsApp_integration.md\n",
      "  -> Successfully saved 003_Mandatory_request_authenticity_via_Meta_signature_verification.md\n",
      "  -> Successfully saved 004_SQLite-backed_minimal_persistence_for_conversation_state.md\n",
      "  -> Successfully saved 005_OpenAI_Assistants_threadsruns_model_for_conversation_management.md\n",
      "  -> Successfully saved 006_Per-user_thread_reuse_via_wa_id-to-thread_id_mapping_policy-dependent.md\n",
      "  -> Successfully saved 007_Meta_Graph_API_payload_construction_and_sending_centralized_in_utils.md\n",
      "  -> Successfully saved 008_ASR_handled_via_standalone_HTTP_pipeline_script_not_in_webhook_path.md\n",
      "  -> Successfully saved 009_Environment-driven_configuration_with_example.env.md\n",
      "  -> Successfully saved 010_Production_hosting_assumption_public_HTTPS_with_Meta_webhook_verification.md\n",
      "  -> Successfully saved 011_Mobile_app_as_a_UI_prototype_not_coupled_to_the_bot.md\n",
      "  -> Successfully saved 012_Explicit_avoidance_of_Google_SpeechRecognition_in_favor_of_external_ASR_API.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/sudokara/SE_Project_3 into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpas7fh_cv...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: src\\phoenix\\CLI\\cli.py\n",
      "  - Reading: src\\phoenix\\Uploader\\OneDrive.py\n",
      "  - Reading: src\\phoenix\\Uploader\\GoogleDrive.py\n",
      "  - Reading: src\\phoenix\\Observation\\EventHandler.py\n",
      "  - Reading: main.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpas7fh_cv...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary is a comprehensive and accurate reflection of the repository's structure and contents. It correctly identifies the project's core capabilities, modular architecture (structured monolith), use of specific design patterns (Strategy, Composite, Singleton), key technology stack components, and indicators of project maturity like ADRs and benchmarking, all of which are directly supported by the provided file and directory names.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 6 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a perfect reflection of the key architectural decisions outlined in the Repository Summary. They accurately document the choices for the Structured Monolith architecture (ADR-001), the extensive use of the Strategy and Composite patterns (ADR-002, ADR-006), the client-side GPG encryption approach (ADR-003), the dual file system monitoring strategies (ADR-004), and the selection of a CLI as the primary interface (ADR-005). Each ADR is logical, plausible, and directly supported by the provided summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\sudokara_SE_Project_3\\dir3'\n",
      "  -> Successfully saved 001_Structured_Monolithic_Architecture.md\n",
      "  -> Successfully saved 002_Strategy_Pattern_for_Core_System_Behaviors.md\n",
      "  -> Successfully saved 003_Client-Side_GPG_Encryption.md\n",
      "  -> Successfully saved 004_Dual-Strategy_File_System_Monitoring.md\n",
      "  -> Successfully saved 005_Command-Line_Interface_CLI_as_Primary_User_Interface.md\n",
      "  -> Successfully saved 006_Composite_Pattern_for_Directory_Representation.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 6 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/sudokara/SE_Project_3 into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpa589u6qu...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: src\\phoenix\\CLI\\cli.py\n",
      "  - Reading: src\\phoenix\\Uploader\\OneDrive.py\n",
      "  - Reading: src\\phoenix\\Uploader\\GoogleDrive.py\n",
      "  - Reading: src\\phoenix\\Observation\\EventHandler.py\n",
      "  - Reading: main.py\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpa589u6qu...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary aligns with the repositoryâ€™s structure and artifacts, accurately describing the strategy-based observation, compression/encryption (GPG+tar), cloud uploaders (Google Drive and OneDrive), CLI orchestration, composite watch directory modeling, logging/CSV auditing, ADRs/UML docs, and benchmarking/notebooks. It also reasonably notes limitations and security concerns evident from committed tokens and logs.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 12 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align closely with the repository summary and capture the key architectural choices: strategy-centric modularity (with CEManager/OManager), inotify vs periodic observation, composite modeling, tar-then-GPG pipeline (with GPG singleton/key strategy), provider abstraction for Google Drive and OneDrive, CLI orchestration, JSON config and on-disk token storage, local staging under .phnx, CSV-based auditing, an MVP-first reliability posture, and documentation artifacts. The Context/Decision/Consequences sections are plausible and consistent with the codebase and stated limitations, without introducing unsupported claims.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\sudokara_SE_Project_3\\dir4'\n",
      "  -> Successfully saved 001_Strategy-centric_modular_architecture.md\n",
      "  -> Successfully saved 002_Linux_inotify_event-driven_monitoring_with_periodic_fallback.md\n",
      "  -> Successfully saved 003_Composite_model_for_watched_directory_trees.md\n",
      "  -> Successfully saved 004_Compression-then-encryption_pipeline_using_tar_and_GPG.md\n",
      "  -> Successfully saved 005_GPG_engine_singleton_and_explicit_key_strategy.md\n",
      "  -> Successfully saved 006_Cloud_provider_abstraction_with_Google_Drive_and_OneDrive_implementations.md\n",
      "  -> Successfully saved 007_Interactive_CLI_as_the_primary_orchestrator.md\n",
      "  -> Successfully saved 008_JSON-based_configuration_and_on-disk_token_storage.md\n",
      "  -> Successfully saved 009_Local_artifact_staging_under_.phnx.md\n",
      "  -> Successfully saved 010_CSV-based_audit_logging_for_events_and_uploads.md\n",
      "  -> Successfully saved 011_MVP-first_reliability_posture_retries_and_resumable_uploads_deferred.md\n",
      "  -> Successfully saved 012_Documentation-driven_development_with_ADRs_UML_and_benchmarks.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 12 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/MLOps into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpcn4u7l_l...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: linear_regression\\mlruns\\0\\2c3f710072934e71b16c3714becbd597\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\7292997940744a0883036895ffb16bd1\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\887a1f02ba2c425da6dfe42b1be730fb\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\937b0dff3bcf4882b5bd90da9c099a6d\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\d65997c0f50845838df7443c0cc091f9\\artifacts\\estimator.html\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpcn4u7l_l...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately interprets the repository's structure, correctly identifies the use of MLflow for experiment tracking, and astutely observes the discrepancy between the project name (`linear_regression`) and the actual model type (a tree-based ensemble) based on the logged hyperparameters in the `mlruns` directory.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 5 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a perfect reflection of the provided Repository Summary. Each ADR addresses a key architectural decision explicitly called out in the summary, including the core choice of MLflow (ADR-1), the modular code structure (ADR-2), the specific model selection (ADR-3), the deployment packaging strategy (ADR-4), and the physical project layout (ADR-5). The 'Context', 'Decision', and 'Consequences' sections in each ADR are logical and directly supported by the analysis in the summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_MLOps\\dir3'\n",
      "  -> Successfully saved 001_Adoption_of_MLflow_for_MLOps-Centric_Experiment_Management.md\n",
      "  -> Successfully saved 002_Implementation_of_a_Modular_Component-Based_Code_Structure.md\n",
      "  -> Successfully saved 003_Use_of_Ensemble_Models_Over_Simple_Linear_Models.md\n",
      "  -> Successfully saved 004_Standardized_Model_Packaging_for_Deployment_Readiness.md\n",
      "  -> Successfully saved 005_Physical_Separation_of_Code_Data_and_Experiment_Artifacts.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 5 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/MLOps into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp9ytlkw2w...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: linear_regression\\mlruns\\0\\2c3f710072934e71b16c3714becbd597\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\7292997940744a0883036895ffb16bd1\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\887a1f02ba2c425da6dfe42b1be730fb\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\937b0dff3bcf4882b5bd90da9c099a6d\\artifacts\\estimator.html\n",
      "  - Reading: linear_regression\\mlruns\\0\\d65997c0f50845838df7443c0cc091f9\\artifacts\\estimator.html\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp9ytlkw2w...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary aligns with the repository structure and MLflow artifacts shown. It correctly identifies a regression workflow with MLflow tracking, RandomForest-like parameters and metrics, the presence of estimator.html and model artifacts, CSV data files, and the committed mlruns directory. While some parts are labeled as â€œlikely/assumed,â€ they are reasonable given the file names and contents.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 14 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs closely match the repository summary. They capture the key decisions around MLflow usage (local tracking, autologging, per-run env capture, model packaging), the modular pipeline structure, the choice of scikit-learn RandomForestRegressor, CSV-based data handling, in-code configuration, dual persistence, script-based orchestration, training-only metrics, co-locating data/artifacts, and the lack of CI/testing. The contexts and consequences are plausible and consistent with the observed repository contents.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_MLOps\\dir4'\n",
      "  -> Successfully saved 001_Local_MLflow_tracking_with_committed_mlruns.md\n",
      "  -> Successfully saved 002_Modular_pipeline_by_functional_layers.md\n",
      "  -> Successfully saved 003_Tree-ensemble_regressor_as_default_model.md\n",
      "  -> Successfully saved 004_Plain_CSV_ingestion_without_schema_or_versioning.md\n",
      "  -> Successfully saved 005_Training-only_metrics_logged.md\n",
      "  -> Successfully saved 006_Dual_model_persistence_custom_save_and_MLflow_model_logging.md\n",
      "  -> Successfully saved 007_Script-based_orchestration_without_a_workflow_engine.md\n",
      "  -> Successfully saved 008_In-code_configuration_instead_of_external_config.md\n",
      "  -> Successfully saved 009_Per-run_environment_capture_via_MLflow_without_project-level_manifest.md\n",
      "  -> Successfully saved 010_MLflow_autologging_for_scikit-learn.md\n",
      "  -> Successfully saved 011_Estimator_visualization_artifact_logging.md\n",
      "  -> Successfully saved 012_Co-locating_data_and_experiment_artifacts_with_source_code.md\n",
      "  -> Successfully saved 013_No_CICD_tests_or_code_quality_automation.md\n",
      "  -> Successfully saved 014_Relying_on_MLflow_model_packaging_for_serving.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 14 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/Reddit-clone into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmppzo6gmkz...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: frontend\\package-lock.json\n",
      "  - Reading: backend\\package-lock.json\n",
      "  - Reading: backend\\routes\\greddit.js\n",
      "  - Reading: backend\\routes\\post.js\n",
      "  - Reading: backend\\routes\\user.js\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmppzo6gmkz...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately deduces the project's architecture (React frontend, Node.js backend, Nginx proxy), technology stack (Vite, Express, Tailwind, TypeScript), and core features based on the provided file and directory structure. All claims are well-supported by the evidence.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 6 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a perfect representation of the provided Repository Summary. Each ADR accurately identifies a key architectural decisionâ€”from the overall containerization strategy and the choice of a React SPA to the specifics of the Nginx proxy, JWT authentication, monolithic Node.js backend with MongoDB, and the hybrid file storage approach. The context, decision, and consequences for each ADR are logical, well-articulated, and directly supported by the details in the summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_Reddit-clone\\dir3'\n",
      "  -> Successfully saved 001_Multi-Service_Containerized_Architecture.md\n",
      "  -> Successfully saved 002_React-based_Single-Page_Application_SPA_for_the_Frontend.md\n",
      "  -> Successfully saved 003_Nginx_Reverse_Proxy_as_Gateway_and_Router.md\n",
      "  -> Successfully saved 004_Stateless_Token-Based_Authentication_JWT.md\n",
      "  -> Successfully saved 005_Monolithic_Node.js_Backend_with_a_NoSQL_Database.md\n",
      "  -> Successfully saved 006_Hybrid_File_Storage_Strategy_for_User_Uploads.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 6 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/Reddit-clone into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpsx6py5_6...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: frontend\\package-lock.json\n",
      "  - Reading: backend\\package-lock.json\n",
      "  - Reading: backend\\routes\\greddit.js\n",
      "  - Reading: backend\\routes\\post.js\n",
      "  - Reading: backend\\routes\\user.js\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpsx6py5_6...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary contains several unverified or speculative claims (e.g., JWT-based auth, Axios usage, Fuse.js/UUID/qs utilities, Multer specifics, cascade deletes, and voting/keyword enforcement details) that arenâ€™t confirmed by the provided context.\n",
      "\n",
      "FEEDBACK: Re-write the summary to stick strictly to what is observable in the repository:\n",
      "- Confirm authentication mechanism by checking backend/package.json and routes/login.js (JWT vs sessions) before stating it.\n",
      "- Verify the HTTP client in the frontend (axios vs fetch) via frontend/package.json and src code.\n",
      "- Confirm database/ODM by inspecting backend/schema.js and backend/package.json (Mongoose) and describe docker-compose.ymlâ€™s actual services (e.g., whether MongoDB is defined).\n",
      "- Validate file upload handling by checking for Multer or other middleware; note the presence of backend/public assets but avoid inferring upload details without code evidence.\n",
      "- Do not claim features like cascade deletes, vote toggling logic, banned keyword enforcement, or data population unless they are clearly implemented in backend/routes/*.js and schema.js.\n",
      "- Acknowledge backend/onedrive.js if it is relevant to storage.\n",
      "- Keep infrastructure claims (Nginx reverse proxy, Dockerfiles) aligned with the actual configs in nginx/default.conf and Dockerfiles.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: frontend\\package-lock.json\n",
      "  - Reading: backend\\package-lock.json\n",
      "  - Reading: backend\\routes\\greddit.js\n",
      "  - Reading: backend\\routes\\post.js\n",
      "  - Reading: backend\\routes\\user.js\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpsx6py5_6...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary includes unverified specifics about dependencies and route capabilities that arenâ€™t evidenced by the provided file/directory listing.\n",
      "FEEDBACK: Remove or soften claims that rely on package-lock.json contents (e.g., Mongoose, JWT, Multer, CORS, React Router) and route behaviors (e.g., voting endpoints, image handling specifics). Instead, state only what the structure confirms: a Node/Express backend with Jade views and route files (index.js, login.js, user.js, greddit.js, post.js, report.js), a frontend using Vite + React + TypeScript with Tailwind configs and the listed components/routes, static asset directories under backend/public, and Docker/Nginx configs present. If you want to mention dependencies or auth/storage mechanisms, flag them as unknown pending inspection of package.json, package-lock.json, and route source files.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 3 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: frontend\\package-lock.json\n",
      "  - Reading: backend\\package-lock.json\n",
      "  - Reading: backend\\routes\\greddit.js\n",
      "  - Reading: backend\\routes\\post.js\n",
      "  - Reading: backend\\routes\\user.js\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpsx6py5_6...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately reflects the repositoryâ€™s structure: a Dockerâ€‘composed Node/Express backend with Jade views, a Vite + React + TypeScript frontend using Tailwind, and an Nginx layer, along with correctly inferred features from route and file names while avoiding unverifiable specifics.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 11 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align with the repository summary, covering containerized multi-service orchestration, Nginx as static server/reverse proxy, a Vite/React/TypeScript SPA with Tailwind, an Express backend with Jade views, domain-oriented routing, monorepo structure, frontend typing/linting vs backend JS, SPA routing fallback, separate static pipelines, and a centralized schema module. They avoid asserting an unknown database choice and keep claims (e.g., optional OneDrive integration, public media directories) plausible given the files present.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_Reddit-clone\\dir4'\n",
      "  -> Successfully saved 001_Containerized_multi-service_architecture_orchestrated_with_Docker_Compose.md\n",
      "  -> Successfully saved 002_Nginx_fronting_the_stack_as_static_server_and_reverse_proxy.md\n",
      "  -> Successfully saved 003_SPA_frontend_built_with_Vite_React_and_TypeScript.md\n",
      "  -> Successfully saved 004_NodeExpress_backend_using_classic_Express-generator_structure_with_Jade_views.md\n",
      "  -> Successfully saved 005_Public_filesystem-based_media_storage_with_optional_external_storage_integration.md\n",
      "  -> Successfully saved 006_Domain-oriented_routing_and_UI_structure.md\n",
      "  -> Successfully saved 007_Monorepo_with_clear_service_boundaries.md\n",
      "  -> Successfully saved 008_Frontend_type_safety_and_linting_backend_JavaScript_without_TypeScript.md\n",
      "  -> Successfully saved 009_SPA-compatible_hosting_and_navigation_fallback.md\n",
      "  -> Successfully saved 010_Separate_static_asset_pipelines_for_backend_and_frontend.md\n",
      "  -> Successfully saved 011_Centralized_backend_schema_module_for_model_definitions.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 11 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/need-for-speed into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp59wm_ob7...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: package-lock.json\n",
      "  - Reading: src\\main.js\n",
      "  - Reading: src\\cartrack.js\n",
      "  - Reading: src\\racetrack.js\n",
      "  - Reading: index.html\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp59wm_ob7...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT:\n",
      "FEEDBACK: The summary claims the project includes `stats.js` for performance monitoring. However, there is no evidence of this dependency or file in the provided repository context. Please regenerate the summary ensuring all stated technologies and libraries are explicitly present in the file list.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: package-lock.json\n",
      "  - Reading: src\\main.js\n",
      "  - Reading: src\\cartrack.js\n",
      "  - Reading: src\\racetrack.js\n",
      "  - Reading: index.html\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmp59wm_ob7...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately identifies the project as a 3D web-based racing game, correctly infers the technology stack (Three.js, Vite) from the file structure and asset types, and correctly deduces the modular architecture and core functionalities based on the names and organization of the source files and 3D assets.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 5 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a high-quality representation of the project's architecture as described in the summary. They accurately capture all the major architectural pillars mentioned: the choice of Three.js for rendering, Vite for the build system, procedural generation for the racetrack, a DOM overlay for the UI, and GLTF as the standard asset format. The context, decisions, and consequences for each ADR are logical and directly supported by the provided text.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_need-for-speed\\dir3'\n",
      "  -> Successfully saved 001_Adoption_of_Three.js_for_Core_3D_Rendering.md\n",
      "  -> Successfully saved 002_Procedural_Generation_for_Racetrack_Creation.md\n",
      "  -> Successfully saved 003_Vite_as_the_Build_Tool_and_Development_Server.md\n",
      "  -> Successfully saved 004_DOM_Overlay_for_UI_and_Game_State_Management.md\n",
      "  -> Successfully saved 005_Standardization_on_GLTF_for_3D_Assets.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 5 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/adyanshkakran/need-for-speed into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpzborch_4...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: package-lock.json\n",
      "  - Reading: src\\main.js\n",
      "  - Reading: src\\cartrack.js\n",
      "  - Reading: src\\racetrack.js\n",
      "  - Reading: index.html\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpzborch_4...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary asserts many specific features (AI opponents, miniâ€‘map camera, stats.js overlay, detailed HUD, input bindings, Frenet-frame/Catmullâ€“Rom implementation, multiâ€‘material road, camera toggles, and exact tool/version numbers) that are not evidenced by the provided repository context.\n",
      "\n",
      "FEEDBACK: Regenerate the summary using only what can be confirmed from the repo:\n",
      "- Verify tooling and versions from package.json (e.g., Three.js, Vite) before stating them.\n",
      "- Describe index.html contents only after inspecting its actual UI/HUD elements and scripts.\n",
      "- Summarize src/main.js, racetrack.js, cartrack.js, car.js, and fuel.js based on their real code; donâ€™t assume AI, miniâ€‘map, controls, or physics unless present.\n",
      "- For track generation, mention splines/Frenet frames/UV tiling/multiâ€‘materials only if explicitly implemented in racetrack.js/cartrack.js.\n",
      "- Confirm stats.js usage, multiple cameras, and collision systems from imports and code.\n",
      "- List assets in public/ without inferring gameplay features from them.\n",
      "- Keep â€œBuild and Runâ€ steps aligned with actual npm scripts in package.json.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 2 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: package-lock.json\n",
      "  - Reading: src\\main.js\n",
      "  - Reading: src\\cartrack.js\n",
      "  - Reading: src\\racetrack.js\n",
      "  - Reading: index.html\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpzborch_4...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary asserts specific tooling, package name, and dependency versions that are not verifiable from the provided file/directory listing alone.\n",
      "FEEDBACK: Remove unverified claims about the project name (â€œcar-racingâ€), exact dependencies (three, stats.js), versions, ES module type, Vite as the build tool, and npm scripts or build/run commands unless you inspect package.json and source files. Reframe the summary to:\n",
      "- Confirm only what the structure shows: a web project with index.html, style.css, src/*.js (main.js, racetrack.js, cartrack.js, car.js, fuel.js), and a public directory containing multiple GLTF models/textures for cars, a stadium, and related images.\n",
      "- Note that the assets suggest a 3D car-themed scene, but usage and runtime libraries are not confirmed without source inspection.\n",
      "- Avoid calling public assets â€œserved by Viteâ€ unless Vite is verified.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 3 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Re-generating summary with feedback...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: package-lock.json\n",
      "  - Reading: src\\main.js\n",
      "  - Reading: src\\cartrack.js\n",
      "  - Reading: src\\racetrack.js\n",
      "  - Reading: index.html\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpzborch_4...\n",
      "-> Verification Result: INCORRECT\n",
      "Feedback Received: INCORRECT: The summary asserts many specifics (e.g., orthographic miniâ€‘map, OrbitControls, Stats.js overlay, Catmullâ€“Rom spline track generation, AI cars, boundingâ€‘box collisions, detailed HUD fields, â€œNeed for Speedâ€ reference, project name) that are not supported by the provided file/directory listing.\n",
      "\n",
      "FEEDBACK: Regenerate the summary to rely only on verifiable facts from the repository context. Explicitly confirm tech stack and tooling by reading package.json, and UI details by reading index.html. Describe src modules and public assets based on their filenames without inferring implementation details (camera types, spline math, AI, collisions, HUD metrics). Avoid claims about specific behaviors unless you can cite them from the actual code in src/*.js or the HTML.\n",
      "\n",
      "âŒ Summary incorrect. Will attempt to regenerate.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 14 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align well with the repository summary and cover the key architectural decisions: Three.js for rendering, ES modules with Vite, centralized orchestration in main.js, dual-camera and dual-renderer setup, procedural track generation via Catmullâ€“Rom and Frenet frames with custom BufferGeometry/UVs, coexistence of racetrack.js and cartrack.js, AABB collisions, DOM-based HUD, GLTF assets from public/, lightweight arcade physics via parameters, reuse of the spline path for placement/AI, and inclusion of OrbitControls and Stats.js. The Context/Decision/Consequences sections are plausible and consistent with the described code and assets.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\adyanshkakran_need-for-speed\\dir4'\n",
      "  -> Successfully saved 001_Three.js_for_browser-based_3D_rendering.md\n",
      "  -> Successfully saved 002_Modern_tooling_with_ES_modules_and_Vite.md\n",
      "  -> Successfully saved 003_Monolithic_scene_orchestration_in_main.js.md\n",
      "  -> Successfully saved 004_Dual-camera_system_with_orthographic_minimap.md\n",
      "  -> Successfully saved 005_Two-canvas_two-renderer_layout.md\n",
      "  -> Successfully saved 006_Procedural_racetrack_via_CatmullRom_spline_and_Frenet_frames.md\n",
      "  -> Successfully saved 007_Custom_BufferGeometry_with_indexed_vertices_and_tiled_UVs.md\n",
      "  -> Successfully saved 008_Coexistence_of_racetrack.js_and_cartrack.js.md\n",
      "  -> Successfully saved 009_Simple_collision_detection_via_bounding_boxes.md\n",
      "  -> Successfully saved 010_DOM-based_HUD_and_menus_overlay.md\n",
      "  -> Successfully saved 011_GLTFGLB_assets_served_from_public_via_Vite_static_hosting.md\n",
      "  -> Successfully saved 012_Lightweight_arcade_physics_tuned_via_parameters.md\n",
      "  -> Successfully saved 013_Reuse_of_spline_path_for_AI_and_pickup_placement.md\n",
      "  -> Successfully saved 014_Inclusion_of_OrbitControls_and_Stats.js_in_runtime.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 14 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gemini-2.5-pro\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gemini-2.5-pro\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/Moya/Moya into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpgkt434r1...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: Changelog.md\n",
      "  - Reading: Readme.md\n",
      "  - Reading: Readme_CN.md\n",
      "  - Reading: docs\\Examples\\Response.md\n",
      "  - Reading: docs\\Examples\\Basic.md\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpgkt434r1...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately identifies the repository as the Moya Swift networking library, correctly detailing its core dependency on Alamofire, its support for multiple dependency managers (CocoaPods, Carthage, SPM), its robust CI/CD and tooling setup (CircleCI, SwiftLint, Danger), and its extensive documentation, including internationalization (docs_CN).\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 6 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs are a perfect representation of the repository summary. They accurately identify and document the six most critical architectural decisions that define the Moya library: its core enum-based design, its relationship with Alamofire, its plugin architecture, its testability through stubbing, its support for reactive paradigms, and its professional-grade project infrastructure. Each ADR's Context, Decision, and Consequences are logical and directly supported by the provided summary.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\Moya_Moya\\dir3'\n",
      "  -> Successfully saved 001_Enum-based_API_Endpoint_Definition.md\n",
      "  -> Successfully saved 002_Abstraction_Layer_over_Alamofire.md\n",
      "  -> Successfully saved 003_Plugin-Based_Architecture_for_Extensibility.md\n",
      "  -> Successfully saved 004_First-Class_Support_for_Network_Stubbing.md\n",
      "  -> Successfully saved 005_Dedicated_Support_for_Reactive_Programming_Paradigms.md\n",
      "  -> Successfully saved 006_Multi-Platform_Dependency_Management_and_CICD.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gimini. 6 ADRs were generated and saved.\n",
      "Initializing the Orchestrator Agent...\n",
      "Initializing with model: gpt-5\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing SummaryCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrWriterAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Initializing AdrCheckerAgent...\n",
      "Initializing LLMCaller with model: gpt-5\n",
      "Orchestrator is ready with all subordinate agents.\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting Orchestration Workflow\n",
      "==================================================\n",
      "Cloning https://github.com/Moya/Moya into temporary directory C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpglt28t4l...\n",
      "Cloning successful.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ Summary Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "\n",
      "Analyzing repository structure...\n",
      "\n",
      "Summarizing the 5 largest files...\n",
      "  - Reading: Changelog.md\n",
      "  - Reading: Readme.md\n",
      "  - Reading: Readme_CN.md\n",
      "  - Reading: docs\\Examples\\Response.md\n",
      "  - Reading: docs\\Examples\\Basic.md\n",
      "Verifying summary against the code in C:\\Users\\rudra\\AppData\\Local\\Temp\\tmpglt28t4l...\n",
      "-> Verification Result: CORRECT\n",
      "Feedback Received: CORRECT: The summary accurately describes Moyaâ€™s purpose, architecture, capabilities, modules (core and Combine), plugin system, testing/stubbing, documentation breadth (including CN), examples, tooling/CI, and multiâ€‘PM support. It aligns with the repositoryâ€™s structure and docs, including reactive integrations and migration guides.\n",
      "\n",
      "âœ… Summary confirmed accurate. Proceeding to ADR generation.\n",
      "--------------------------------------------------\n",
      "ðŸ”¥ ADR Generation Attempt 1 of 3\n",
      "--------------------------------------------------\n",
      "Extracting design decisions from the summary...\n",
      "Successfully extracted 11 design decisions.\n",
      "Verifying generated ADRs against the summary...\n",
      "-> Verification Result: ADRs are CORRECT\n",
      "Feedback Received: CORRECT: The ADRs align closely with the repository summary and cover the core architectural choices: layering over Alamofire/URLSession, TargetType-driven endpoint modeling, Task/Endpoint request composition, plugin-based cross-cutting concerns, first-class stubbing with sampleData, strong Response/MoyaError types, provider pattern with trackInflights, optional reactive modules, hidden transport with sanctioned extension points, multi-package-manager distribution, and documentation/migration emphasis. The contexts, decisions, and consequences are plausible and reflect documented trade-offs (e.g., plugin ordering, low-level tuning limits, trackInflights race fixes, maintenance overhead for multiple package managers and reactive modules). No contradictions with the summary are present, and the ADR set captures the most important architectural decisions described.\n",
      "\n",
      "âœ… ADRs confirmed accurate.\n",
      "\n",
      "==================================================\n",
      "ðŸ’¾ Saving verified ADRs to disk...\n",
      "Saving final ADRs to directory: 'D:\\LAB\\ADR\\AgenticAdr\\Generated_ADRs\\Moya_Moya\\dir4'\n",
      "  -> Successfully saved 001_Abstraction_Over_AlamofireURLSession.md\n",
      "  -> Successfully saved 002_Endpoint_Modeling_via_TargetType.md\n",
      "  -> Successfully saved 003_Request_Composition_via_Task_and_Endpoint.md\n",
      "  -> Successfully saved 004_Plugin-Based_Cross-Cutting_Architecture.md\n",
      "  -> Successfully saved 005_First-Class_Stubbing_and_Sample_Data.md\n",
      "  -> Successfully saved 006_Optional_Reactive_Integrations_as_Separate_Targets.md\n",
      "  -> Successfully saved 007_Strong_Response_and_Error_Types.md\n",
      "  -> Successfully saved 008_Provider_Pattern_with_Inflight_Request_Deduplication.md\n",
      "  -> Successfully saved 009_Transport_Details_Hidden_with_Extension_Points.md\n",
      "  -> Successfully saved 010_Multi-Package-Manager_Distribution.md\n",
      "  -> Successfully saved 011_Documentation-First_and_Migration-Guided_Releases.md\n",
      "\n",
      "ðŸŽ‰ Orchestration Workflow Finished Successfully!\n",
      "==================================================\n",
      "\n",
      "Process complete with Gpt. 11 ADRs were generated and saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Repository URL\n",
    "https://github.com/karthikv1392/cs6401_se.git\"\n",
    "https://github.com/sa4s-serc/HarmonE\n",
    "https://github.com/srini1978/carbonQL\n",
    "https://github.com/srini1978/AzureCognitiveSearchDemo\n",
    "https://github.com/likhithkanigolla/LLMOps-Platform\n",
    "https://github.com/likhithkanigolla/CAPS-IIITH\n",
    "https://github.com/sa4s-serc/EdgeMLBalancer\n",
    "https://github.com/sa4s-serc/switch\n",
    "https://github.com/sa4s-serc/EcoMLS\n",
    "https://github.com/sa4s-serc/AdaMLS\n",
    "https://github.com/akhiha/juice-shop\n",
    "https://gitlab.com/20a_akhila/amazon-clone\n",
    "https://gitlab.com/20a_akhila/movie-database\n",
    "https://gitlab.com/20a_akhila/silly_story_generator\n",
    "https://github.com/sambuaneesh/why-py\n",
    "https://github.com/montycloud/moya\n",
    "https://github.com/stanfordnlp/dspy\n",
    "https://github.com/miryala10sathvika/Food-delivery\n",
    "https://github.com/miryala10sathvika/Drawingeditor\n",
    "https://github.com/legend479/HARPP\n",
    "https://github.com/divyanash911/RSS-Reader\n",
    "https://github.com/divyanash911/design-for-social-innovation-project\n",
    "https://github.com/OSDG-IIITH/CabMiloge\n",
    "https://github.com/sudokara/monkeytpe-contest\n",
    "https://github.com/sudokara/bracket\n",
    "https://github.com/sudokara/SpecFlow\n",
    "https://github.com/microsoft/sarathi-serve\n",
    "https://github.com/Poorvi-HC/DIP-Project\n",
    "https://github.com/adyanshkakran/RL_project\n",
    "https://github.com/adyanshkakran/Shravana\n",
    "https://github.com/sudokara/SE_Project_3\n",
    "https://github.com/adyanshkakran/MLOps\n",
    "https://github.com/adyanshkakran/Reddit-clone\n",
    "https://github.com/adyanshkakran/need-for-speed\n",
    "https://github.com/Moya/Moya\n",
    "https://github.com/sismics/music\n",
    "https://github.com/ameykaran/esell/\n",
    "https://github.com/yashaswinee/QuizAppMicroservices/tree/microservices\n",
    "https://github.com/ShailenderGoyal/Enigmatrix_Salesforce_Hackathon\n",
    "https://github.com/someyuck/Project-Kuch-Bhi\n",
    "https://github.com/ShailenderGoyal/PageRank-Algorithm\n",
    "\"\"\"\n",
    "\n",
    "repos = [\"https://github.com/yashaswinee/QuizAppMicroservices\",\n",
    "         \"https://github.com/ShailenderGoyal/Enigmatrix_Salesforce_Hackathon\",\n",
    "         \"https://github.com/someyuck/Project-Kuch-Bhi\",\n",
    "         \"https://github.com/ShailenderGoyal/PageRank-Algorithm\"]\n",
    "\n",
    "\n",
    "for repo_url_to_process in repos:\n",
    "    generate_adrs(repo_url_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c18234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
